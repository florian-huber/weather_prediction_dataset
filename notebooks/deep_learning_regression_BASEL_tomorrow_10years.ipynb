{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brief-stanford",
   "metadata": {},
   "source": [
    "# Weather prediction dataset - regression task: tomorrow sunshine hours \n",
    "\n",
    "### (Using full 10 years of weather prediction dataset)\n",
    "\n",
    "Code examples rougly sorted from simple dense neural networks (only dense layers), to more complex networks that include `Dropout` and/or `BatchNormalization` to prevent overfitting.\n",
    "\n",
    "Second part contains examples on how to apply `Monte-Carlo Dropout` to evaluate the model uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = os.path.dirname(os.getcwd())\n",
    "path_data = os.path.join(path_root, \"dataset\")\n",
    "filename_data = os.path.join(path_data, \"weather_prediction_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "list({x.split(\"_\")[0] for x in data.columns if x not in [\"MONTH\", \"DATE\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-november",
   "metadata": {},
   "source": [
    "# Split data into data (X) and labels (y)\n",
    "We here want to predict the sunshine hours for a particular place (say BASEL which is about in the center of all 18 locations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_data = data.loc[:(data.shape[0]-2)].drop(columns=['DATE', 'MONTH'])\n",
    "\n",
    "# labels (sunshine hours the next day)\n",
    "y_data = data.loc[1:][\"BASEL_sunshine\"]\n",
    "\n",
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-mineral",
   "metadata": {},
   "source": [
    "# Split data into training, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print(f\"Data split into training ({X_train.shape[0]}),\" \\\n",
    "      f\" validation ({X_val.shape[0]}) and test set ({X_test.shape[0]}).\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also shuffled the data!\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-producer",
   "metadata": {},
   "source": [
    "# 1) Start simple: Build small neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-characterization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(input)\n",
    "    layers_dense = keras.layers.Dense(5, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=input, outputs=output, name=\"weather_prediction_model\")\n",
    "\n",
    "n_features = X_data.shape[1]\n",
    "n_predictions = 1\n",
    "\n",
    "model = create_nn(n_features, n_predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-consumption",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=200,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df['root_mean_squared_error'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['mae']])\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-craft",
   "metadata": {},
   "source": [
    "## Evaluate the model on the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 12))\n",
    "\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "#plt.savefig(\"sunshine_tomorrow_training_test_10years.png\", dpi=300)\n",
    "plt.savefig(\"sunshine_tomorrow_training_test_10years.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-commerce",
   "metadata": {},
   "source": [
    "## Use the validation set to monitor the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_nn(n_features=X_train.shape[1], n_predictions=1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-princess",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 200,\n",
    "                    validation_data=(X_val, y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "\n",
    "plt.savefig(\"training_history_2_rmse_10years.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-awareness",
   "metadata": {},
   "source": [
    "## Multiple observations --> somethings wrong with training!\n",
    "- Severe overfitting! (validation loss >> training loss)\n",
    "- No smooth learning process: Large jumps in losses over epochs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-canyon",
   "metadata": {},
   "source": [
    "# Improve network -> Remedy 1: make network smaler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(input)\n",
    "    layers_dense = keras.layers.Dense(5, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=input, outputs=output, name=\"small_prediction_model\")\n",
    "\n",
    "n_features = X_data.shape[1]\n",
    "n_predictions = 1\n",
    "\n",
    "model = create_nn(n_features, n_predictions)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-prerequisite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 200,\n",
    "                    validation_data=(X_val, y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-marketplace",
   "metadata": {},
   "source": [
    "## --> here: works a bit, when size is reduced A LOT! But still clearly overfitting..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-olympus",
   "metadata": {},
   "source": [
    "# Improve network ->  Remedy 2: early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=10,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "model = create_nn(n_features=X_train.shape[1], n_predictions=1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 200,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-graduate",
   "metadata": {},
   "source": [
    "# Improve network ->  Remedy 3: add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    layers_input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.Dense(100, 'relu')(layers_input)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense)\n",
    "    layers_dense = keras.layers.Dense(50, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    layers_output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=layers_input, outputs=layers_output, name=\"dropout_prediction_model\")\n",
    "\n",
    "model = create_nn(X_data.shape[1], 1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-option",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=20,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 200,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-hobby",
   "metadata": {},
   "source": [
    "# Compare to naive guess: tomorrow has same sunshine hours as today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(X_train[\"DUSSELDORF_sunshine\"], y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(X_test[\"DUSSELDORF_sunshine\"], y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-overhead",
   "metadata": {},
   "source": [
    "# Improve network ->  Remedy 4: Use Dropout and BatchNormalization\n",
    "- ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    layers_input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.BatchNormalization()(layers_input)\n",
    "    layers_dense = keras.layers.Dense(100, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense)\n",
    "    layers_dense = keras.layers.Dense(50, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense)\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    layers_output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=layers_input, outputs=layers_output, name=\"dropout_prediction_model\")\n",
    "\n",
    "model = create_nn(X_data.shape[1], 1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-arena",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=20,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 1000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-premiere",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-bubble",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "- lowering learning rate makes training progress smoother\n",
    "- overfitting is still very clearly visible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-holiday",
   "metadata": {},
   "source": [
    "# 2) Optional teaching expansion: model uncertainty\n",
    "## Using Monte-Carlo Dropout to evaluate model uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    layers_input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.BatchNormalization()(layers_input)\n",
    "    layers_dense = keras.layers.Dense(100, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(50, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    layers_output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=layers_input, outputs=layers_output, name=\"dropout_prediction_model\")\n",
    "\n",
    "model = create_nn(X_data.shape[1], 1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-portsmouth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=20,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 1000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-carolina",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[1].set_ylabel(\"true sunshine hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-latex",
   "metadata": {},
   "source": [
    "## Compute scores for multiple runs\n",
    "- The model will look differntly each time due to Dropout randomly removing nodes. This can be seen as a ensemble of slightly different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_ensemble = 100\n",
    "y_test_predicted_ensemble = np.zeros((X_test.shape[0], n_ensemble))\n",
    "\n",
    "for i in tqdm(range(n_ensemble)):\n",
    "    y_test_predicted_ensemble[:, i] = model.predict(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test_predicted_ensemble[0,:], rwidth=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-cabinet",
   "metadata": {},
   "source": [
    "### Take mean and standard deviation of the computed scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_mean = np.mean(y_test_predicted_ensemble, axis=1)\n",
    "y_test_predicted_std = np.std(y_test_predicted_ensemble, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_std.min(), y_test_predicted_std.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=100)\n",
    "plt.scatter(y_test_predicted_mean, y_test, s=40*y_test_predicted_std, \n",
    "            c=y_test_predicted_std, alpha=0.5)\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"true values\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('STD of 100 predictions (Monte-Carlo Dropout)', rotation=90, fontsize=10)\n",
    "\n",
    "ax.axis(\"equal\")\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"sunshine_tomorrow_monte_carlo_dropout_10years.png\", dpi=300)\n",
    "plt.savefig(\"sunshine_tomorrow_monte_carlo_dropout_10years.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-district",
   "metadata": {},
   "source": [
    "# Same easier to predict labels 1: global radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y_data = data.loc[1:][\"BASEL_global_radiation\"]\n",
    "\n",
    "predicted_labelname = \"predicted global radiation\"\n",
    "true_labelname = \"true global radiation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-episode",
   "metadata": {},
   "source": [
    "# Split data into training, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print(f\"Data split into training ({X_train.shape[0]}),\" \\\n",
    "      f\" validation ({X_val.shape[0]}) and test set ({X_test.shape[0]}).\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also shuffled the data!\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-tulsa",
   "metadata": {},
   "source": [
    "# Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-cricket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    layers_input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.BatchNormalization()(layers_input)\n",
    "    layers_dense = keras.layers.Dense(100, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(50, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    layers_output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=layers_input, outputs=layers_output, name=\"dropout_prediction_model\")\n",
    "\n",
    "model = create_nn(X_data.shape[1], 1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-truth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=20,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 1000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-overview",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plt.style.use('ggplot')\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(predicted_labelname)\n",
    "axes[0].set_ylabel(true_labelname)\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(predicted_labelname)\n",
    "axes[1].set_ylabel(true_labelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_ensemble = 100\n",
    "y_test_predicted_ensemble = np.zeros((X_test.shape[0], n_ensemble))\n",
    "\n",
    "for i in tqdm(range(n_ensemble)):\n",
    "    y_test_predicted_ensemble[:, i] = model.predict(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test_predicted_ensemble[0,:], rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_mean = np.mean(y_test_predicted_ensemble, axis=1)\n",
    "y_test_predicted_std = np.std(y_test_predicted_ensemble, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_std.min(), y_test_predicted_std.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-princess",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=100)\n",
    "plt.scatter(y_test_predicted_mean, y_test, s=100*y_test_predicted_std, \n",
    "            c=y_test_predicted_std, alpha=0.5)\n",
    "plt.xlabel(predicted_labelname)\n",
    "plt.ylabel(true_labelname)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('STD of 100 predictions (Monte-Carlo Dropout)', rotation=90, fontsize=10)\n",
    "\n",
    "ax.axis(\"equal\")\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"global_radiation_tomorrow_monte_carlo_dropout_10years.png\", dpi=300)\n",
    "plt.savefig(\"global_radiation_tomorrow_monte_carlo_dropout_10years.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-tokyo",
   "metadata": {},
   "source": [
    "# Same, but for easier to predict labels 2: max temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y_data = data.loc[1:][\"BASEL_temp_max\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-prize",
   "metadata": {},
   "source": [
    "# Split data into training, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "print(f\"Data split into training ({X_train.shape[0]}),\" \\\n",
    "      f\" validation ({X_val.shape[0]}) and test set ({X_test.shape[0]}).\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also shuffled the data!\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.max(), y_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-thread",
   "metadata": {},
   "source": [
    "# Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-vulnerability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def create_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    layers_input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.BatchNormalization()(layers_input)\n",
    "    layers_dense = keras.layers.Dense(100, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(50, 'relu')(layers_dense)\n",
    "    layers_dense = keras.layers.Dropout(rate=0.2)(layers_dense, training=True)\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    layers_output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=layers_input, outputs=layers_output, name=\"dropout_prediction_model\")\n",
    "\n",
    "model = create_nn(X_data.shape[1], 1)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-poland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss', mode=\"min\",\n",
    "    patience=20,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 1000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[earlystopper],\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-afghanistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plt.style.use('ggplot')\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sunshine hours\n",
    "y_train_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "plt.style.use('ggplot')\n",
    "axes[0].scatter(y_train_predicted, y_train, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[0].set_title(\"training set\")\n",
    "axes[0].set_xlabel(\"predicted sunshine hours\")\n",
    "axes[0].set_ylabel(\"true sunshine hours\")\n",
    "\n",
    "axes[1].scatter(y_test_predicted, y_test, s=10, alpha=0.5, color=\"teal\")\n",
    "axes[1].set_title(\"test set\")\n",
    "axes[1].set_xlabel(\"predicted max. temperature\")\n",
    "axes[1].set_ylabel(\"true max. temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-challenge",
   "metadata": {},
   "source": [
    "### Compute scores for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_ensemble = 100\n",
    "y_test_predicted_ensemble = np.zeros((X_test.shape[0], n_ensemble))\n",
    "\n",
    "for i in tqdm(range(n_ensemble)):\n",
    "    y_test_predicted_ensemble[:, i] = model.predict(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test_predicted_ensemble[0,:], rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_mean = np.mean(y_test_predicted_ensemble, axis=1)\n",
    "y_test_predicted_std = np.std(y_test_predicted_ensemble, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_std.min(), y_test_predicted_std.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=100)\n",
    "plt.scatter(y_test_predicted_mean, y_test, s=30*y_test_predicted_std, \n",
    "            c=y_test_predicted_std, alpha=0.5)\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"true values\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('STD of 100 predictions (Monte-Carlo Dropout)', rotation=90, fontsize=10)\n",
    "\n",
    "ax.axis(\"equal\")\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"max_temp_tomorrow_monte_carlo_dropout_10years.png\", dpi=300)\n",
    "plt.savefig(\"max_temp_tomorrow_monte_carlo_dropout_10years.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-charge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
